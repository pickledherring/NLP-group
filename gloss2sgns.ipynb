{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# from googleapiclient.discovery import build\n",
    "# from io import FileIO\n",
    "# from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "except:\n",
    "  nltk.download('stopwords')\n",
    "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-01b2337b6ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Get the files from google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrive_service\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get english train data file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "#  Get the files from google drive\n",
    "auth.authenticate_user()\n",
    "drive_service = build('drive', 'v3')\n",
    "\n",
    "# Get english train data file\n",
    "file_id = '1m3Ax9Z8OHMU-7FqraKc-ddI3YQ7yY_Q6'  # file id on the Google Drive\n",
    "downloaded = FileIO(\"en.trial.complete.json\", 'w')\n",
    "request = drive_service.files().get_media(fileId=file_id)\n",
    "downloader = MediaIoBaseDownload(downloaded, request)\n",
    "done = False\n",
    "while done is False:\n",
    "  status, done = downloader.next_chunk()\n",
    "  print(\"Download {}%.\".format(int(status.progress() * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>gloss</th>\n",
       "      <th>example</th>\n",
       "      <th>type</th>\n",
       "      <th>counts</th>\n",
       "      <th>f_rnk</th>\n",
       "      <th>concrete</th>\n",
       "      <th>polysemous</th>\n",
       "      <th>sgns</th>\n",
       "      <th>char</th>\n",
       "      <th>electra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en.trial.1</td>\n",
       "      <td>beautiful</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Pleasant ; clear .</td>\n",
       "      <td>It 's beautiful outside , let 's go for a walk .</td>\n",
       "      <td>synonym/antonym-based</td>\n",
       "      <td>124908</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.393769145, 0.7516670227000001, -2.581333160...</td>\n",
       "      <td>[0.295645088, 0.098426342, 0.0463486575, 0.016...</td>\n",
       "      <td>[0.0800914839, -0.1875839084, -0.0411579385000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en.trial.2</td>\n",
       "      <td>cocktail</td>\n",
       "      <td>noun</td>\n",
       "      <td>A mixture of other substances or things .</td>\n",
       "      <td>a cocktail of illegal drugs</td>\n",
       "      <td>hypernym-based</td>\n",
       "      <td>4187</td>\n",
       "      <td>13245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.0872907639, 0.2617726326, 0.668431639700000...</td>\n",
       "      <td>[0.3878918886, 0.1971583217, -0.44026631120000...</td>\n",
       "      <td>[-1.4771454334, -0.4742421806, 0.0847439319, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en.trial.3</td>\n",
       "      <td>institutionalized</td>\n",
       "      <td>adjective</td>\n",
       "      <td>Having been established as an institution .</td>\n",
       "      <td>It is very difficult to get bureaucracies to a...</td>\n",
       "      <td>paraphrastic</td>\n",
       "      <td>961</td>\n",
       "      <td>35934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.7893871069, -0.43510755900000003, 0.8553860...</td>\n",
       "      <td>[-0.0519028902, 0.2257766128, -0.1839749813, 0...</td>\n",
       "      <td>[-1.1030955315, -0.9046602845, 0.1503403783, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en.trial.4</td>\n",
       "      <td>menial</td>\n",
       "      <td>noun</td>\n",
       "      <td>A servant , especially a domestic servant .</td>\n",
       "      <td>The world was awake to the 2nd of May , but Ma...</td>\n",
       "      <td>hypernym-based</td>\n",
       "      <td>517</td>\n",
       "      <td>53267</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1222261563, 0.1572209597, 0.5396134257, -0....</td>\n",
       "      <td>[-0.3667449057, -0.1431699395, -0.0671329796, ...</td>\n",
       "      <td>[-1.6584062576, -0.24498166140000002, 0.150174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en.trial.5</td>\n",
       "      <td>seek</td>\n",
       "      <td>verb</td>\n",
       "      <td>To try to find ; to look for ; to search for .</td>\n",
       "      <td>Not long ago , it was difficult to produce pho...</td>\n",
       "      <td>paraphrastic</td>\n",
       "      <td>25195</td>\n",
       "      <td>3212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.1894155741, 1.3668279648000001, -1.61634504...</td>\n",
       "      <td>[0.6137102246, 0.5464909673, -0.0161557049, 9....</td>\n",
       "      <td>[-0.5474479198000001, -0.0880863219, 0.0784259...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id               word        pos  \\\n",
       "0  en.trial.1          beautiful  adjective   \n",
       "1  en.trial.2           cocktail       noun   \n",
       "2  en.trial.3  institutionalized  adjective   \n",
       "3  en.trial.4             menial       noun   \n",
       "4  en.trial.5               seek       verb   \n",
       "\n",
       "                                            gloss  \\\n",
       "0                              Pleasant ; clear .   \n",
       "1       A mixture of other substances or things .   \n",
       "2     Having been established as an institution .   \n",
       "3     A servant , especially a domestic servant .   \n",
       "4  To try to find ; to look for ; to search for .   \n",
       "\n",
       "                                             example                   type  \\\n",
       "0   It 's beautiful outside , let 's go for a walk .  synonym/antonym-based   \n",
       "1                        a cocktail of illegal drugs         hypernym-based   \n",
       "2  It is very difficult to get bureaucracies to a...           paraphrastic   \n",
       "3  The world was awake to the 2nd of May , but Ma...         hypernym-based   \n",
       "4  Not long ago , it was difficult to produce pho...           paraphrastic   \n",
       "\n",
       "   counts  f_rnk  concrete  polysemous  \\\n",
       "0  124908    706         0           0   \n",
       "1    4187  13245         1           0   \n",
       "2     961  35934         0           0   \n",
       "3     517  53267         1           1   \n",
       "4   25195   3212         0           0   \n",
       "\n",
       "                                                sgns  \\\n",
       "0  [1.393769145, 0.7516670227000001, -2.581333160...   \n",
       "1  [2.0872907639, 0.2617726326, 0.668431639700000...   \n",
       "2  [0.7893871069, -0.43510755900000003, 0.8553860...   \n",
       "3  [0.1222261563, 0.1572209597, 0.5396134257, -0....   \n",
       "4  [1.1894155741, 1.3668279648000001, -1.61634504...   \n",
       "\n",
       "                                                char  \\\n",
       "0  [0.295645088, 0.098426342, 0.0463486575, 0.016...   \n",
       "1  [0.3878918886, 0.1971583217, -0.44026631120000...   \n",
       "2  [-0.0519028902, 0.2257766128, -0.1839749813, 0...   \n",
       "3  [-0.3667449057, -0.1431699395, -0.0671329796, ...   \n",
       "4  [0.6137102246, 0.5464909673, -0.0161557049, 9....   \n",
       "\n",
       "                                             electra  \n",
       "0  [0.0800914839, -0.1875839084, -0.0411579385000...  \n",
       "1  [-1.4771454334, -0.4742421806, 0.0847439319, -...  \n",
       "2  [-1.1030955315, -0.9046602845, 0.1503403783, -...  \n",
       "3  [-1.6584062576, -0.24498166140000002, 0.150174...  \n",
       "4  [-0.5474479198000001, -0.0880863219, 0.0784259...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df = pd.read_json(\"trial-data_all/en.trial.complete.json\")\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      [clear, pleasant]\n",
       "1                          [substances, things, mixture]\n",
       "2                             [established, institution]\n",
       "3                        [domestic, especially, servant]\n",
       "4                              [look, search, find, try]\n",
       "                             ...                        \n",
       "195                        [color, cells, animal, plant]\n",
       "196                                [seeming, appearance]\n",
       "197       [proceed, travel, person, permission, vehicle]\n",
       "198                      [much, sitting, moving, around]\n",
       "199    [sentence, heraldic, word, forming, achievemen...\n",
       "Name: gloss, Length: 200, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(gloss):\n",
    "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "  cleaned = tokenizer.tokenize(gloss)\n",
    "  cleaned = list(set([word.lower() for word in cleaned]))\n",
    "  cleaned = [word for word in cleaned if not word in stop_words]\n",
    "  return cleaned\n",
    "\n",
    "gloss_lists = en_df.gloss.apply(clean)\n",
    "gloss_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all context words\n",
    "context_voc = []\n",
    "for i in range(len(gloss_lists)):\n",
    "  for j in range(len(gloss_lists[i])):\n",
    "    if not gloss_lists[i][j] in context_voc:\n",
    "      context_voc.append(gloss_lists[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true context words for each defined word (center word)\n",
    "trues = []\n",
    "for i in range(len(gloss_lists)):\n",
    "  for j in range(len(gloss_lists[i])):\n",
    "    index = context_voc.index(gloss_lists[i][j])\n",
    "    # append index of center in gloss_lists, index in context_voc, and 1 for true\n",
    "    trues.append([i, index, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGNS(\n",
       "  (center_embs): Embedding(200, 256, sparse=True)\n",
       "  (context_embs): Embedding(769, 256, sparse=True)\n",
       ")"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostly follows this: https://adoni.github.io/2017/11/08/word2vec-pytorch/\n",
    "class SGNS(nn.Module):\n",
    "    def __init__(self) -> 'SGNS':\n",
    "        super(SGNS, self).__init__()\n",
    "        self.center_embs = nn.Embedding(len(gloss_lists), 256, sparse = True)\n",
    "        self.context_embs = nn.Embedding(len(context_voc), 256, sparse = True)\n",
    "        nn.init.xavier_uniform_(self.center_embs.weight)\n",
    "        nn.init.xavier_uniform_(self.context_embs.weight)\n",
    "    def forward(self, center:'center index', pos_con:'trues index', neg_cons:'list of falses indices')->'scores':\n",
    "        scores = []\n",
    "        center_emb = self.center_embs(torch.LongTensor([center]))\n",
    "        pos_context_emb = self.context_embs(torch.LongTensor([pos_con]))\n",
    "        pos_score = torch.mul(center_emb, pos_context_emb).squeeze()\n",
    "        pos_score = torch.sum(pos_score)\n",
    "        pos_score = nn.functional.logsigmoid(pos_score)\n",
    "        scores.append(pos_score)\n",
    "\n",
    "        for neg_con in neg_cons:\n",
    "            neg_context_emb = self.context_embs(torch.LongTensor([neg_con]))\n",
    "            neg_score = torch.mul(center_emb, neg_context_emb).squeeze()\n",
    "            neg_score = torch.sum(neg_score)\n",
    "            neg_score = nn.functional.logsigmoid(-1 * neg_score)\n",
    "            scores.append(neg_score)\n",
    "\n",
    "        return -1 * sum(torch.stack(scores))\n",
    "        \n",
    "sgns = SGNS()\n",
    "sgns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9947)\n",
      "tensor(0.5099)\n",
      "tensor(0.2892)\n",
      "tensor(0.0315)\n",
      "tensor(0.0481)\n",
      "tensor(0.0313)\n",
      "tensor(0.0370)\n",
      "tensor(0.1617)\n",
      "tensor(0.0303)\n",
      "tensor(0.2597)\n",
      "tensor(0.0151)\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.SparseAdam(sgns.parameters(), lr = .001)\n",
    "\n",
    "# number of negative pairs for each train. 2 - 5 usually works well for large datasets\n",
    "neg_count = 3\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    for j in range(len(gloss_lists)):\n",
    "        optim.zero_grad()\n",
    "        # to add: choice distribution based on frequency raised to 3/4 power\n",
    "        falses = np.random.choice(len(context_voc), neg_count, replace = False)\n",
    "        loss = sgns.forward(trues[i][0], trues[i][1], falses)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 256\n"
     ]
    }
   ],
   "source": [
    "embeddings = sgns.center_embs.weight.tolist()\n",
    "print(len(embeddings), len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09188833087682724, 0.0751756802201271, 0.07847709208726883, 0.06864740699529648, -0.0531768761575222] \n",
      " [-0.4988436103, -0.6650734544, -1.3417009115, 0.5371951461, -0.7869545221]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, en_df.sgns.values)\n",
    "print(X_train[0][:5], \"\\n\", y_train[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
