{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gloss_glove_sgns.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pickledherring/NLP-group/blob/main/gloss_glove_sgns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VylR5pztFBek"
      },
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from io import FileIO\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.losses import cosine_similarity\n",
        "\n",
        "try:\n",
        "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "except:\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpJuiW_RJsPd",
        "outputId": "2c4e13a4-8059-47ed-dbe1-180dfba81346"
      },
      "source": [
        "#  Get the files from google drive\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Get english train data file\n",
        "file_id = '1m3Ax9Z8OHMU-7FqraKc-ddI3YQ7yY_Q6'  # file id on the Google Drive\n",
        "downloaded = FileIO(\"en.trial.complete.json\", 'w')\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  status, done = downloader.next_chunk()\n",
        "  print(\"Download {}%.\".format(int(status.progress() * 100)))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download 100%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "GLOsKlE5YZhd",
        "outputId": "6be4dc66-9f9c-4c72-ab65-b5348087f84c"
      },
      "source": [
        "en_df = pd.read_json(\"en.trial.complete.json\")\n",
        "en_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en.trial.1</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>adjective</td>\n",
              "      <td>Pleasant ; clear .</td>\n",
              "      <td>It 's beautiful outside , let 's go for a walk .</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>124908</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.393769145, 0.7516670227000001, -2.581333160...</td>\n",
              "      <td>[0.295645088, 0.098426342, 0.0463486575, 0.016...</td>\n",
              "      <td>[0.0800914839, -0.1875839084, -0.0411579385000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en.trial.2</td>\n",
              "      <td>cocktail</td>\n",
              "      <td>noun</td>\n",
              "      <td>A mixture of other substances or things .</td>\n",
              "      <td>a cocktail of illegal drugs</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>4187</td>\n",
              "      <td>13245</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[2.0872907639, 0.2617726326, 0.668431639700000...</td>\n",
              "      <td>[0.3878918886, 0.1971583217, -0.44026631120000...</td>\n",
              "      <td>[-1.4771454334, -0.4742421806, 0.0847439319, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en.trial.3</td>\n",
              "      <td>institutionalized</td>\n",
              "      <td>adjective</td>\n",
              "      <td>Having been established as an institution .</td>\n",
              "      <td>It is very difficult to get bureaucracies to a...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>961</td>\n",
              "      <td>35934</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.7893871069, -0.43510755900000003, 0.8553860...</td>\n",
              "      <td>[-0.0519028902, 0.2257766128, -0.1839749813, 0...</td>\n",
              "      <td>[-1.1030955315, -0.9046602845, 0.1503403783, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en.trial.4</td>\n",
              "      <td>menial</td>\n",
              "      <td>noun</td>\n",
              "      <td>A servant , especially a domestic servant .</td>\n",
              "      <td>The world was awake to the 2nd of May , but Ma...</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>517</td>\n",
              "      <td>53267</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.1222261563, 0.1572209597, 0.5396134257, -0....</td>\n",
              "      <td>[-0.3667449057, -0.1431699395, -0.0671329796, ...</td>\n",
              "      <td>[-1.6584062576, -0.24498166140000002, 0.150174...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en.trial.5</td>\n",
              "      <td>seek</td>\n",
              "      <td>verb</td>\n",
              "      <td>To try to find ; to look for ; to search for .</td>\n",
              "      <td>Not long ago , it was difficult to produce pho...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>25195</td>\n",
              "      <td>3212</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.1894155741, 1.3668279648000001, -1.61634504...</td>\n",
              "      <td>[0.6137102246, 0.5464909673, -0.0161557049, 9....</td>\n",
              "      <td>[-0.5474479198000001, -0.0880863219, 0.0784259...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                            electra\n",
              "0  en.trial.1  ...  [0.0800914839, -0.1875839084, -0.0411579385000...\n",
              "1  en.trial.2  ...  [-1.4771454334, -0.4742421806, 0.0847439319, -...\n",
              "2  en.trial.3  ...  [-1.1030955315, -0.9046602845, 0.1503403783, -...\n",
              "3  en.trial.4  ...  [-1.6584062576, -0.24498166140000002, 0.150174...\n",
              "4  en.trial.5  ...  [-0.5474479198000001, -0.0880863219, 0.0784259...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXf9jjhQZYsd",
        "outputId": "c2a2b406-5d02-48dd-dad1-bf37d9310a48"
      },
      "source": [
        "en_df.dtypes"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            object\n",
              "word          object\n",
              "pos           object\n",
              "gloss         object\n",
              "example       object\n",
              "type          object\n",
              "counts         int64\n",
              "f_rnk          int64\n",
              "concrete       int64\n",
              "polysemous     int64\n",
              "sgns          object\n",
              "char          object\n",
              "electra       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "KEgGA7Svaev6",
        "outputId": "509b8fba-c1ce-432c-ac50-1ba53556336b"
      },
      "source": [
        "en_df[en_df.word.duplicated()]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>en.trial.67</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To legally dissolve a marriage between two peo...</td>\n",
              "      <td>A ship captain can marry couples , but can not...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[0.0899147466, 0.0271891933, 0.023069024100000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>en.trial.189</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Then Proclamation was made , that they that ha...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-1.0183763504, -0.3864063621, 0.0048319194, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                            electra\n",
              "66    en.trial.67  ...  [0.0899147466, 0.0271891933, 0.023069024100000...\n",
              "188  en.trial.189  ...  [-1.0183763504, -0.3864063621, 0.0048319194, -...\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mvjqzJ2c-zo"
      },
      "source": [
        "we have words to disambiguate! forthwith looks to be the same with a different example though. <br>thoughts on disambiguation (feel free to add):<br><br> need to gather contex, but all I can think of is to train the NN to find the part of speech of the word and maybe type. I think we are only given the gloss and from that predict the embedding, so we (maybe) can't use the rest of it except in training. probably a good idea regardless of the disambiguation goal. <br><br> we could also retrain the model on incorrect words that are polysemous, like a boosting method. <br><br> lastly, disambiguation might not be necessary given the gloss and the vector might not be so similar. should look at the distance between these words in the embeddings. glosses look different, but I can see the top few elements of these two polysemous words are similar in all of the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "UUZHwbOJa7gR",
        "outputId": "844cc10a-4843-490d-bb56-fd60d9e67973"
      },
      "source": [
        "en_df[(en_df.word == \"divorce\") | (en_df.word == \"forthwith\")]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>en.trial.51</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To separate something that was connected .</td>\n",
              "      <td>The radical group voted to divorce itself from...</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[-0.6520454288, -0.1928912848, 0.0298318155, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>en.trial.67</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To legally dissolve a marriage between two peo...</td>\n",
              "      <td>A ship captain can marry couples , but can not...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[0.0899147466, 0.0271891933, 0.023069024100000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>en.trial.161</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Let ther be Light , said God , and forthwith L...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-0.9691627026, -0.20675842460000002, 0.184671...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>en.trial.189</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Then Proclamation was made , that they that ha...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-1.0183763504, -0.3864063621, 0.0048319194, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                            electra\n",
              "50    en.trial.51  ...  [-0.6520454288, -0.1928912848, 0.0298318155, -...\n",
              "66    en.trial.67  ...  [0.0899147466, 0.0271891933, 0.023069024100000...\n",
              "160  en.trial.161  ...  [-0.9691627026, -0.20675842460000002, 0.184671...\n",
              "188  en.trial.189  ...  [-1.0183763504, -0.3864063621, 0.0048319194, -...\n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFI8k1rjr9Dg"
      },
      "source": [
        "clean glosses of punctuation, stopwords, duplicates, turn into lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvRWJPm6b5fl",
        "outputId": "2a54154e-9a36-4b53-99b1-c2350ff5c49e"
      },
      "source": [
        "def clean(gloss):\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  cleaned = tokenizer.tokenize(gloss)\n",
        "  cleaned = list(set([word.lower() for word in cleaned]))\n",
        "  cleaned = [word for word in cleaned if not word in stop_words]\n",
        "  return cleaned\n",
        "\n",
        "gloss_lists = en_df.gloss.apply(clean)\n",
        "gloss_lists"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                      [clear, pleasant]\n",
              "1                          [substances, things, mixture]\n",
              "2                             [established, institution]\n",
              "3                        [domestic, especially, servant]\n",
              "4                              [look, try, search, find]\n",
              "                             ...                        \n",
              "195                        [animal, color, plant, cells]\n",
              "196                                [seeming, appearance]\n",
              "197       [vehicle, permission, proceed, person, travel]\n",
              "198                      [sitting, around, moving, much]\n",
              "199    [word, phrase, heraldic, achievement, part, se...\n",
              "Name: gloss, Length: 200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQUe5WlPYp1Y"
      },
      "source": [
        "# list of all context words\n",
        "context_voc = []\n",
        "for i in range(len(gloss_lists)):\n",
        "  for j in range(len(gloss_lists[i])):\n",
        "    if not gloss_lists[i][j] in context_voc:\n",
        "      context_voc.append(gloss_lists[i][j])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JGKH5E-vwQC"
      },
      "source": [
        "based on an SGNS following this guide: https://medium.com/towards-datascience/word2vec-negative-sampling-made-easy-7a1a647e07a4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DyMl1dZEfgT"
      },
      "source": [
        "# true context words for each defined word (center word)\n",
        "trues = []\n",
        "for i in range(len(gloss_lists)):\n",
        "  for j in range(len(gloss_lists[i])):\n",
        "    index = context_voc.index(gloss_lists[i][j])\n",
        "    # append index of center in gloss_lists, index of context in context_voc, and 1 for true\n",
        "    trues.append([i, index, 1])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9M3aObkcu_K",
        "outputId": "a1e2af01-8c6a-4a96-b805-ca899b8486a1"
      },
      "source": [
        "trues[:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1], [0, 1, 1], [1, 2, 1], [1, 3, 1], [1, 4, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovGY7fAy_eCQ"
      },
      "source": [
        "this could be improved by weighting the selection by the count of the word raised to 3/4 over the sum of the counts of all words raised to 3/4.\n",
        "\n",
        "we can also try resampling with each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uYJxuODc4AP"
      },
      "source": [
        "falses = []\n",
        "# create 3 randomly sampled context words for each true context word\n",
        "# these may be true, but probably not. we'll label them false\n",
        "for i in range(len(trues)):\n",
        "  for j in range(3):\n",
        "    center_index = trues[i][0]\n",
        "    context_index = random.sample(range(len(context_voc)), 1)[0]\n",
        "    falses.append([center_index, context_index, 0])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEQabsrdXcRF"
      },
      "source": [
        "def gen_onehot():\n",
        "  # combine and shuffle trues and falses\n",
        "  together = np.concatenate((np.array(trues), np.array(falses)))\n",
        "  np.random.shuffle(together)\n",
        "  targets = torch.Tensor(together).long()\n",
        "\n",
        "  # matrices to one hot encode middle words and target words\n",
        "  middle_tensor = torch.zeros(targets.shape[0], gloss_lists.shape[0])\n",
        "  context_tensor = torch.zeros(targets.shape[0], len(context_voc))\n",
        "\n",
        "  for i in range(middle_tensor.shape[0]):\n",
        "    middle_tensor[i, targets[i, 0]] = 1\n",
        "    context_tensor[i, targets[i, 1]] = 1\n",
        "\n",
        "  labels = targets[:, 2].float()\n",
        "  return (middle_tensor, context_tensor, labels)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skMwCw5NwAnm"
      },
      "source": [
        "build the model itself below. not sure why bias needs to be false, should try as true.\n",
        "\n",
        "this would be more elegant as a class or at least a function combined with the forward (dot product production) part included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le4qUvU8kV0U"
      },
      "source": [
        "# fully connected middle layers for middle and target words\n",
        "mid_fc = torch.nn.Linear(gloss_lists.shape[0], 256, bias = False)\n",
        "con_fc = torch.nn.Linear(len(context_voc), 256, bias = False)\n",
        "torch.nn.init.xavier_uniform_(mid_fc.weight)\n",
        "torch.nn.init.xavier_uniform_(con_fc.weight)\n",
        "sig = torch.nn.Sigmoid()\n",
        "params = list(mid_fc.parameters()) + list(con_fc.parameters())\n",
        "optim = torch.optim.Adam(params, lr = .001)\n",
        "loss_fn = torch.nn.BCELoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jnIqilFD1F9"
      },
      "source": [
        "epochs = 100\n",
        "mid_hot, con_hot, labels = gen_onehot()\n",
        "\n",
        "for i in range(epochs):\n",
        "  trans_mid = mid_fc(torch.Tensor(mid_hot))\n",
        "  trans_con = con_fc(torch.Tensor(con_hot))\n",
        "  dot_mat = torch.zeros(mid_hot.shape[0], 1)\n",
        "  # for each row dot a center embedding by a target embedding\n",
        "  for j in range(len(trans_mid)):\n",
        "    dot_mat[j, :] = trans_mid[j, :] @ trans_con[j, :]\n",
        "  # sigmoid transformation, then compute the gradient and backwards propagate\n",
        "  prob_mat = sig(dot_mat)\n",
        "  prob_mat.requires_grad = True\n",
        "  optim.zero_grad()\n",
        "  loss = loss_fn(prob_mat, torch.Tensor(labels).view(prob_mat.shape[0], 1))\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  # print loss every 10 epochs\n",
        "  if i % 10 == 0:\n",
        "    print(loss.data)\n",
        "  mid_hot, con_hot, labels = gen_onehot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AiZcEtt1vEa",
        "outputId": "8fcda248-f281-4e61-d90a-39de157a136d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "print(loss.data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6936)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpazIQI8Dhnr"
      },
      "source": [
        "embeddings = mid_fc.weight.t().detach().numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, en_df.word)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WcmjmRcD9iU",
        "outputId": "ec5f0818-3f10-4381-fdc6-98a8becef57b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#print(X_test.shape, \"\\n\", y_test.shape)\n",
        "print(\"xtrain: \", X_train, \"\\nytrain: \", y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtrain:  [[-0.08244613  0.05170777 -0.10481814 ... -0.05728389 -0.02333343\n",
            "  -0.0198084 ]\n",
            " [-0.06401545  0.03203784  0.10222124 ... -0.00624143 -0.00557776\n",
            "  -0.01500468]\n",
            " [-0.08806799  0.03453511  0.11092366 ...  0.05850323  0.03197394\n",
            "  -0.02470952]\n",
            " ...\n",
            " [ 0.10356567 -0.00278639  0.00043946 ... -0.10813225 -0.04634301\n",
            "  -0.06341793]\n",
            " [-0.01858965  0.0857036   0.0029063  ... -0.09698204  0.05720955\n",
            "   0.07247003]\n",
            " [ 0.00333329 -0.0653206   0.05320363 ... -0.08313783 -0.03336279\n",
            "  -0.0164146 ]] \n",
            "ytrain:  119      previous\n",
            "10        scraggy\n",
            "25           lull\n",
            "123      cover-up\n",
            "124       version\n",
            "          ...    \n",
            "116         grape\n",
            "199         motto\n",
            "102       caravan\n",
            "54     seriocomic\n",
            "76           ride\n",
            "Name: word, Length: 150, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occtmJHGL5Y5"
      },
      "source": [
        "X_train = np.asarray( X_train, dtype = np.float32 )\n",
        "y_train = np.asarray( y_train, dtype = np.float32 )\n",
        "X_test = np.asarray( X_test, dtype = np.float32 )\n",
        "y_test = np.asarray( y_test, dtype = np.float32 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ABTQJWn7Hzl"
      },
      "source": [
        "NN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6axU1Mqa6PXp"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(256,), dtype=\"float64\")\n",
        "\n",
        "x = layers.Dropout(0.1)(inputs)\n",
        "\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "\n",
        "predictions = layers.Dense(256, activation=\"tanh\", name=\"predictions\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4V5LUo87Vt6"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__KR5QmI7TbF",
        "outputId": "68452642-4b56-4e06-8138-214a088f0a72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "# Fit the model using the train and test datasets.\n",
        "model.fit(X_train, y_train, epochs=epochs)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-927704849cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Fit the model using the train and test datasets.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node binary_crossentropy/Cast\n (defined at /usr/local/lib/python3.7/dist-packages/keras/losses.py:1797)\n]] [Op:__inference_train_function_736]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node binary_crossentropy/Cast:\nIn[0] IteratorGetNext (defined at /usr/local/lib/python3.7/dist-packages/keras/engine/training.py:866)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-44-927704849cb1>\", line 4, in <module>\n>>>     model.fit(X_train, y_train, epochs=epochs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n>>>     y, y_pred, sample_weight, regularization_losses=self.losses)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1797, in binary_crossentropy\n>>>     y_true = tf.cast(y_true, y_pred.dtype)\n>>> "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxjBq0uu7Yx8"
      },
      "source": [
        "Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KROsW7vE7bzk"
      },
      "source": [
        "Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB5UIgEg7bHA"
      },
      "source": [
        "#cosine_loss(y_true, y_pred).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeBX17Pl7ehU"
      },
      "source": [
        "Mean Squared Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEUSgIH6752g"
      },
      "source": [
        "#mean_squared_error(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}