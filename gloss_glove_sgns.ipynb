{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gloss_glove_sgns.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOWXdb9olbPBlu9+50PQ3l/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pickledherring/NLP-group/blob/main/gloss_glove_sgns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VylR5pztFBek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827b3147-6e44-486c-922d-b48c69b4acc0"
      },
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from io import FileIO\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "except:\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpJuiW_RJsPd",
        "outputId": "d2482c77-3a99-4e37-c8ca-e3fc74c1bf07"
      },
      "source": [
        "#  Get the files from google drive\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Get english train data file\n",
        "file_id = '1m3Ax9Z8OHMU-7FqraKc-ddI3YQ7yY_Q6'  # file id on the Google Drive\n",
        "downloaded = FileIO(\"en.trial.complete.json\", 'w')\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "  status, done = downloader.next_chunk()\n",
        "  print(\"Download {}%.\".format(int(status.progress() * 100)))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download 100%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "GLOsKlE5YZhd",
        "outputId": "ad15984e-f87c-4bce-8906-16e022029934"
      },
      "source": [
        "en_df = pd.read_json(\"en.trial.complete.json\")\n",
        "en_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en.trial.1</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>adjective</td>\n",
              "      <td>Pleasant ; clear .</td>\n",
              "      <td>It 's beautiful outside , let 's go for a walk .</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>124908</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.393769145, 0.7516670227000001, -2.581333160...</td>\n",
              "      <td>[0.295645088, 0.098426342, 0.0463486575, 0.016...</td>\n",
              "      <td>[0.0800914839, -0.1875839084, -0.0411579385000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en.trial.2</td>\n",
              "      <td>cocktail</td>\n",
              "      <td>noun</td>\n",
              "      <td>A mixture of other substances or things .</td>\n",
              "      <td>a cocktail of illegal drugs</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>4187</td>\n",
              "      <td>13245</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[2.0872907639, 0.2617726326, 0.668431639700000...</td>\n",
              "      <td>[0.3878918886, 0.1971583217, -0.44026631120000...</td>\n",
              "      <td>[-1.4771454334, -0.4742421806, 0.0847439319, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en.trial.3</td>\n",
              "      <td>institutionalized</td>\n",
              "      <td>adjective</td>\n",
              "      <td>Having been established as an institution .</td>\n",
              "      <td>It is very difficult to get bureaucracies to a...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>961</td>\n",
              "      <td>35934</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.7893871069, -0.43510755900000003, 0.8553860...</td>\n",
              "      <td>[-0.0519028902, 0.2257766128, -0.1839749813, 0...</td>\n",
              "      <td>[-1.1030955315, -0.9046602845, 0.1503403783, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en.trial.4</td>\n",
              "      <td>menial</td>\n",
              "      <td>noun</td>\n",
              "      <td>A servant , especially a domestic servant .</td>\n",
              "      <td>The world was awake to the 2nd of May , but Ma...</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>517</td>\n",
              "      <td>53267</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.1222261563, 0.1572209597, 0.5396134257, -0....</td>\n",
              "      <td>[-0.3667449057, -0.1431699395, -0.0671329796, ...</td>\n",
              "      <td>[-1.6584062576, -0.24498166140000002, 0.150174...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en.trial.5</td>\n",
              "      <td>seek</td>\n",
              "      <td>verb</td>\n",
              "      <td>To try to find ; to look for ; to search for .</td>\n",
              "      <td>Not long ago , it was difficult to produce pho...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>25195</td>\n",
              "      <td>3212</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.1894155741, 1.3668279648000001, -1.61634504...</td>\n",
              "      <td>[0.6137102246, 0.5464909673, -0.0161557049, 9....</td>\n",
              "      <td>[-0.5474479198000001, -0.0880863219, 0.0784259...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                            electra\n",
              "0  en.trial.1  ...  [0.0800914839, -0.1875839084, -0.0411579385000...\n",
              "1  en.trial.2  ...  [-1.4771454334, -0.4742421806, 0.0847439319, -...\n",
              "2  en.trial.3  ...  [-1.1030955315, -0.9046602845, 0.1503403783, -...\n",
              "3  en.trial.4  ...  [-1.6584062576, -0.24498166140000002, 0.150174...\n",
              "4  en.trial.5  ...  [-0.5474479198000001, -0.0880863219, 0.0784259...\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXf9jjhQZYsd",
        "outputId": "27149e50-7f9f-40b5-d2ce-35229c805cf7"
      },
      "source": [
        "en_df.dtypes"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            object\n",
              "word          object\n",
              "pos           object\n",
              "gloss         object\n",
              "example       object\n",
              "type          object\n",
              "counts         int64\n",
              "f_rnk          int64\n",
              "concrete       int64\n",
              "polysemous     int64\n",
              "sgns          object\n",
              "char          object\n",
              "electra       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "KEgGA7Svaev6",
        "outputId": "ae0dcc72-b70a-438a-d1fc-c4e58b9c61d1"
      },
      "source": [
        "en_df[en_df.word.duplicated()]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>en.trial.67</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To legally dissolve a marriage between two peo...</td>\n",
              "      <td>A ship captain can marry couples , but can not...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[0.0899147466, 0.0271891933, 0.023069024100000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>en.trial.189</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Then Proclamation was made , that they that ha...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-1.0183763504, -0.3864063621, 0.0048319194, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                            electra\n",
              "66    en.trial.67  ...  [0.0899147466, 0.0271891933, 0.023069024100000...\n",
              "188  en.trial.189  ...  [-1.0183763504, -0.3864063621, 0.0048319194, -...\n",
              "\n",
              "[2 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mvjqzJ2c-zo"
      },
      "source": [
        "we have words to disambiguate! forthwith looks to be the same with a different example though. <br>thoughts on disambiguation (feel free to add):<br><br> need to gather contex, but all I can think of is to train the NN to find the part of speech of the word and maybe type. I think we are only given the gloss and from that predict the embedding, so we (maybe) can't use the rest of it except in training. probably a good idea regardless of the disambiguation goal. <br><br> we could also retrain the model on incorrect words that are polysemous, like a boosting method. <br><br> lastly, disambiguation might not be necessary given the gloss and the vector might not be so similar. should look at the distance between these words in the embeddings. glosses look different, but I can see the top few elements of these two polysemous words are similar in all of the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "UUZHwbOJa7gR",
        "outputId": "f621c748-af18-4d86-e61b-632b96821a47"
      },
      "source": [
        "en_df[(en_df.word == \"divorce\") | (en_df.word == \"forthwith\")]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>gloss</th>\n",
              "      <th>example</th>\n",
              "      <th>type</th>\n",
              "      <th>counts</th>\n",
              "      <th>f_rnk</th>\n",
              "      <th>concrete</th>\n",
              "      <th>polysemous</th>\n",
              "      <th>sgns</th>\n",
              "      <th>char</th>\n",
              "      <th>electra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>en.trial.51</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To separate something that was connected .</td>\n",
              "      <td>The radical group voted to divorce itself from...</td>\n",
              "      <td>hypernym-based</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[-0.6520454288, -0.1928912848, 0.0298318155, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>en.trial.67</td>\n",
              "      <td>divorce</td>\n",
              "      <td>verb</td>\n",
              "      <td>To legally dissolve a marriage between two peo...</td>\n",
              "      <td>A ship captain can marry couples , but can not...</td>\n",
              "      <td>paraphrastic</td>\n",
              "      <td>21171</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.579477787, -1.7040250301, 2.4623465538, -0....</td>\n",
              "      <td>[-0.09191438560000001, -0.0440451615, -0.45280...</td>\n",
              "      <td>[0.0899147466, 0.0271891933, 0.023069024100000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>en.trial.161</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Let ther be Light , said God , and forthwith L...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-0.9691627026, -0.20675842460000002, 0.184671...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>en.trial.189</td>\n",
              "      <td>forthwith</td>\n",
              "      <td>adverb</td>\n",
              "      <td>Without delay ; immediately .</td>\n",
              "      <td>Then Proclamation was made , that they that ha...</td>\n",
              "      <td>synonym/antonym-based</td>\n",
              "      <td>1179</td>\n",
              "      <td>31462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.7841670513, 0.6406752467, -1.0482375622, -0...</td>\n",
              "      <td>[-8.645650000000001e-05, 0.161273554, 0.082766...</td>\n",
              "      <td>[-1.0183763504, -0.3864063621, 0.0048319194, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  ...                                            electra\n",
              "50    en.trial.51  ...  [-0.6520454288, -0.1928912848, 0.0298318155, -...\n",
              "66    en.trial.67  ...  [0.0899147466, 0.0271891933, 0.023069024100000...\n",
              "160  en.trial.161  ...  [-0.9691627026, -0.20675842460000002, 0.184671...\n",
              "188  en.trial.189  ...  [-1.0183763504, -0.3864063621, 0.0048319194, -...\n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFI8k1rjr9Dg"
      },
      "source": [
        "clean glosses of punctuation, stopwords, duplicates, turn into lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvRWJPm6b5fl",
        "outputId": "ad8bbfc5-fbed-4ee6-cc17-23f96014efe4"
      },
      "source": [
        "def clean(gloss):\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  cleaned = tokenizer.tokenize(gloss)\n",
        "  cleaned = list(set([word.lower() for word in cleaned]))\n",
        "  cleaned = [word for word in cleaned if not word in stop_words]\n",
        "  return cleaned\n",
        "\n",
        "gloss_lists = en_df.gloss.apply(clean)\n",
        "gloss_lists"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                      [clear, pleasant]\n",
              "1                          [mixture, things, substances]\n",
              "2                             [established, institution]\n",
              "3                        [servant, domestic, especially]\n",
              "4                              [try, look, search, find]\n",
              "                             ...                        \n",
              "195                        [plant, cells, animal, color]\n",
              "196                                [appearance, seeming]\n",
              "197       [vehicle, travel, permission, proceed, person]\n",
              "198                      [moving, around, much, sitting]\n",
              "199    [word, forming, achievement, heraldic, sentenc...\n",
              "Name: gloss, Length: 200, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQUe5WlPYp1Y"
      },
      "source": [
        "# list of all context words\n",
        "context_voc = []\n",
        "for i in range(len(gloss_lists)):\n",
        "  for j in range(len(gloss_lists[i])):\n",
        "    if not gloss_lists[i][j] in context_voc:\n",
        "      context_voc.append(gloss_lists[i][j])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JGKH5E-vwQC"
      },
      "source": [
        "based on an SGNS following this guide: https://medium.com/towards-datascience/word2vec-negative-sampling-made-easy-7a1a647e07a4\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DyMl1dZEfgT"
      },
      "source": [
        "# true context words for each defined word (center word)\n",
        "trues = []\n",
        "for i in range(len(gloss_lists)):\n",
        "  for j in range(len(gloss_lists[i])):\n",
        "    index = context_voc.index(gloss_lists[i][j])\n",
        "    # append index of center in gloss_lists, index of context in context_voc, and 1 for true\n",
        "    trues.append([i, index, 1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9M3aObkcu_K",
        "outputId": "fad0ad87-5377-4dc1-fbac-a1dad2553e8e"
      },
      "source": [
        "trues[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 1], [0, 1, 1], [1, 2, 1], [1, 3, 1], [1, 4, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovGY7fAy_eCQ"
      },
      "source": [
        "this could be improved by weighting the selection by the count of the word raised to 3/4 over the sum of the counts of all words raised to 3/4.\n",
        "\n",
        "we can also try resampling with each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uYJxuODc4AP"
      },
      "source": [
        "falses = []\n",
        "# create 3 randomly sampled context words for each true context word\n",
        "# these may be true, but probably not. we'll label them false\n",
        "for i in range(len(trues)):\n",
        "  for j in range(3):\n",
        "    center_index = trues[i][0]\n",
        "    context_index = random.sample(range(len(context_voc)), 1)[0]\n",
        "    falses.append([center_index, context_index, 0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEQabsrdXcRF"
      },
      "source": [
        "def gen_onehot():\n",
        "  # combine and shuffle trues and falses\n",
        "  together = np.concatenate((np.array(trues), np.array(falses)))\n",
        "  np.random.shuffle(together)\n",
        "  targets = torch.as_tensor(together)\n",
        "\n",
        "  # matrices to one hot encode middle words and target words\n",
        "  middle_tensor = torch.zeros(targets.shape[0], gloss_lists.shape[0])\n",
        "  context_tensor = torch.zeros(targets.shape[0], len(context_voc))\n",
        "\n",
        "  for i in range(middle_tensor.shape[0]):\n",
        "    middle_tensor[i, targets[i, 0]] = 1\n",
        "    context_tensor[i, targets[i, 1]] = 1\n",
        "\n",
        "  labels = targets[:, 2].float()\n",
        "  return (middle_tensor, context_tensor, labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skMwCw5NwAnm"
      },
      "source": [
        "build the model itself below. not sure why bias needs to be false, should try as true.\n",
        "\n",
        "this would be more elegant as a class or at least a function combined with the forward (dot product production) part included."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le4qUvU8kV0U"
      },
      "source": [
        "# fully connected middle layers for middle and target words\n",
        "mid_fc = torch.nn.Linear(gloss_lists.shape[0], 256, bias = False)\n",
        "con_fc = torch.nn.Linear(len(context_voc), 256, bias = False)\n",
        "sig = torch.nn.Sigmoid()\n",
        "params = list(mid_fc.parameters()) + list(con_fc.parameters())\n",
        "optim = torch.optim.Adam(params, lr = .001)\n",
        "loss_fn = torch.nn.BCELoss()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jnIqilFD1F9",
        "outputId": "e8ab16b4-196c-4415-9461-b8165c61803b"
      },
      "source": [
        "epochs = 100\n",
        "mid_hot, con_hot, labels = gen_onehot()\n",
        "for i in range(epochs):\n",
        "  trans_mid = mid_fc(mid_hot)\n",
        "  trans_con = con_fc(con_hot)\n",
        "  dot_mat = torch.zeros(mid_hot.shape[0], 1)\n",
        "  # for each row dot a center embedding by a target embedding\n",
        "  for j in range(len(trans_mid)):\n",
        "    dot_mat[j, :] = trans_mid[j, :] @ trans_con[j, :]\n",
        "  # sigmoid transformation, then compute the gradient and backwards propagate\n",
        "  prob_mat = sig(dot_mat)\n",
        "  optim.zero_grad()\n",
        "  loss = loss_fn(prob_mat, torch.Tensor(labels).view(prob_mat.shape[0], 1))\n",
        "  loss.backward()\n",
        "  optim.step()\n",
        "\n",
        "  # print loss every 10 epochs\n",
        "  if i % 10 == 0:\n",
        "    print(loss.data)\n",
        "  mid_hot, con_hot, labels = gen_onehot()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6932)\n",
            "tensor(0.6690)\n",
            "tensor(0.6393)\n",
            "tensor(0.5999)\n",
            "tensor(0.5495)\n",
            "tensor(0.4892)\n",
            "tensor(0.4224)\n",
            "tensor(0.3541)\n",
            "tensor(0.2894)\n",
            "tensor(0.2323)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AiZcEtt1vEa",
        "outputId": "89fbcaf7-9cd3-43ed-b847-88ef075edf67"
      },
      "source": [
        "print(loss.data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1893)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.1411513 , -0.11774216, -0.10432833, -0.1687036 ,  0.1566767 ,\n",
              "       -0.11107994, -0.12471368,  0.15332888,  0.15980025, -0.13986713,\n",
              "        0.12381111, -0.18713355,  0.07512406,  0.08450958, -0.13047186,\n",
              "       -0.12404388, -0.03525103,  0.07027913, -0.16128404,  0.17018603,\n",
              "        0.15817115,  0.16028467, -0.07011227,  0.16349585, -0.11943942,\n",
              "       -0.13224588,  0.01074382, -0.14261241,  0.14661738,  0.0774352 ,\n",
              "       -0.08099443, -0.04730928, -0.16103853,  0.1803701 ,  0.1545418 ,\n",
              "       -0.08406659, -0.1280773 , -0.15287724,  0.09027255,  0.13854425,\n",
              "        0.12404647,  0.17152335, -0.10203484, -0.17817739, -0.15218218,\n",
              "        0.06690591,  0.08689253,  0.1528855 , -0.17611659,  0.15164353,\n",
              "        0.10886443,  0.15343897, -0.16868179,  0.14526094,  0.06567025,\n",
              "       -0.17030992,  0.0192152 , -0.12299297, -0.10162177,  0.1290196 ,\n",
              "       -0.08774319,  0.10496914,  0.1691124 , -0.15756284, -0.16245049,\n",
              "        0.06867835, -0.11665383, -0.06564275,  0.1681042 ,  0.09339084,\n",
              "       -0.12149399,  0.13412927,  0.02953587,  0.01386757, -0.13153088,\n",
              "        0.17544135,  0.14498687,  0.11550216,  0.06916323,  0.15358928,\n",
              "        0.08637942,  0.04011531,  0.10281528, -0.17417115, -0.06745911,\n",
              "       -0.15961657,  0.19541453,  0.15037899, -0.05969139, -0.1746529 ,\n",
              "       -0.18559077,  0.1230982 ,  0.05606531,  0.15587872,  0.13685977,\n",
              "       -0.1211814 , -0.13379273, -0.16497415,  0.162752  ,  0.13934314,\n",
              "        0.12197005, -0.06992571,  0.09942389,  0.09544563,  0.13207234,\n",
              "       -0.18048362, -0.1593071 ,  0.13721742, -0.11488743,  0.18232971,\n",
              "       -0.19837062,  0.15522148, -0.15332739,  0.12481579,  0.03455979,\n",
              "       -0.13948862,  0.1641082 , -0.12482108, -0.16439629, -0.07564649,\n",
              "       -0.16110139, -0.15112443, -0.05374806,  0.1699631 , -0.18340634,\n",
              "        0.18412058,  0.00690649,  0.11210199, -0.127492  , -0.16633461,\n",
              "       -0.08162963,  0.07086222, -0.17000131,  0.175778  ,  0.15146981,\n",
              "        0.05210165, -0.16843396,  0.1745324 ,  0.09183816,  0.03707995,\n",
              "       -0.18541491,  0.1743614 , -0.1701971 ,  0.15185729,  0.08604524,\n",
              "        0.12587938, -0.10571577, -0.1463582 ,  0.07758135, -0.16719167,\n",
              "       -0.02402104, -0.11657966, -0.18174797,  0.16478728,  0.14471503,\n",
              "        0.11205214,  0.13174598, -0.13747203, -0.13849784, -0.05360225,\n",
              "       -0.08988712, -0.16413943, -0.17021647, -0.11953619,  0.09681952,\n",
              "        0.15225865,  0.16888514,  0.10593703, -0.1802891 ,  0.16177188,\n",
              "        0.10337151,  0.18609615,  0.14274901,  0.06023204, -0.16675901,\n",
              "        0.15208524,  0.03236957,  0.13326764,  0.13856615,  0.1760435 ,\n",
              "       -0.06200586,  0.11367711, -0.11714339,  0.02814466, -0.17112675,\n",
              "       -0.18002976,  0.11720441,  0.14124954, -0.12251978, -0.16203   ,\n",
              "       -0.10290156,  0.16329588, -0.1494059 ,  0.08994827, -0.02431948,\n",
              "       -0.04716111, -0.14196153, -0.11327887, -0.15403391,  0.18080953,\n",
              "       -0.17713526,  0.16821373, -0.17655945,  0.11426144, -0.09226339,\n",
              "        0.17778613,  0.02924092, -0.0646256 ,  0.12817805,  0.16889645,\n",
              "        0.07278029,  0.15782015,  0.14367794,  0.15256093, -0.08714268,\n",
              "       -0.17932603, -0.17777282, -0.09099876,  0.09693276,  0.14970714,\n",
              "       -0.0410587 ,  0.16570567,  0.17323604,  0.170337  ,  0.14639686,\n",
              "        0.16043942,  0.17541356,  0.16360202, -0.1628378 ,  0.09059547,\n",
              "        0.08679936,  0.07946885,  0.18779653, -0.14261077, -0.11577757,\n",
              "        0.09513078,  0.1189341 , -0.19588919,  0.09259813,  0.12378796,\n",
              "       -0.16787031,  0.03440145, -0.14010033,  0.02468896, -0.10421925,\n",
              "        0.05936838, -0.13132109, -0.07099694, -0.09889573,  0.09252347,\n",
              "        0.18144114, -0.16562714,  0.10249095, -0.06486448,  0.16163446,\n",
              "       -0.12581474], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpazIQI8Dhnr",
        "outputId": "ed0c7cfa-7fc4-49c7-edca-7b6d04947819"
      },
      "source": [
        "embeddings = mid_fc.weight.t().detach().numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(embeddings, en_df.word)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.15594737,  0.16757499, -0.15409352, ..., -0.08538463,\n",
              "        -0.11705005, -0.12314182],\n",
              "       [ 0.11836023,  0.18111967,  0.16036275, ..., -0.08697964,\n",
              "        -0.13469538,  0.1456157 ],\n",
              "       [ 0.1762775 , -0.17557818, -0.11354394, ...,  0.16546732,\n",
              "         0.1399769 ,  0.14017747],\n",
              "       ...,\n",
              "       [-0.14293912,  0.18295081,  0.03600238, ...,  0.14055118,\n",
              "        -0.1383612 ,  0.18642117],\n",
              "       [-0.1411513 , -0.11774216, -0.10432833, ..., -0.06486448,\n",
              "         0.16163446, -0.12581474],\n",
              "       [ 0.10709661,  0.15535395, -0.06540873, ..., -0.18325497,\n",
              "        -0.15104418, -0.14411506]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WcmjmRcD9iU",
        "outputId": "c7efdb79-fd9d-478b-c072-ad89fbd15e34"
      },
      "source": [
        "print(X_test.shape, \"\\n\", y_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 256) \n",
            " (50,)\n"
          ]
        }
      ]
    }
  ]
}